{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielblins/palestra_gdg/blob/main/notebooks/GoogleExtended_MaritacaLangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integração Maritaca - Langchain\n",
        "\n",
        "Temos um LLM para chamar de nosso! Os desenvolvedores da https://www.maritaca.ai estão de parabéns pelo excelente trabalho desenvolvido.\n",
        "\n",
        "O objetivo deste notebook é demonstrar como integrar o LLM ao Langchain considerando as chamadas a API que estão disponíveis no momento, que é a inferência apenas, não há possibilidade de obter os embeddings, mas acho que é uma questão de tempo até o time disponibilizar essa funcionalidade.\n",
        "\n",
        "Vamos ao que interessa."
      ],
      "metadata": {
        "id": "vhfhLRR_gdJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Software base\n",
        "Vamos instalar o langchain e algumas outras coisas"
      ],
      "metadata": {
        "id": "sDQljnkZhQun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xPT4kaRggZPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce666a9-7543-447e-979d-2148d699d455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q langchain unstructured pinecone-client openai tiktoken python-dotenv faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 1 - Criar um custom LLM\n",
        "\n",
        "Para mais informações sobre como o Langchain funciona, sugiro ler a documentação do produto. Aqui vamos focar na integração com o Maritaca.\n",
        "\n",
        "De todo o modo, o primeiro passo é criar uma extensão da classe LLM e assim entregar ao ambiente do langchain um objeto que \"sabe\" fazer chamadas ao Maritaca. Segundo a documentação, é preciso implementar o método _call que recebe uma string, executa a chamada ao LLM e retorna outra string como saída.\n",
        "\n",
        "Já que o nome do modelo é MariTalk, vamos usar esse nome para nossa classe especial."
      ],
      "metadata": {
        "id": "W2_EpgWkhyGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVFq1LiSZh02",
        "outputId": "e95faef4-00f8-4b7b-ba4b-7f054b1b4dcd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from requests.adapters import HTTPAdapter, Retry\n",
        "from langchain.llms.base import LLM\n",
        "\n",
        "import requests\n",
        "\n",
        "class MaritalkLLM(LLM):\n",
        "\n",
        "  @property\n",
        "  def _llm_type(self) -> str:\n",
        "    return \"custom\"\n",
        "\n",
        "  def _call(\n",
        "    self,\n",
        "    prompt: str,\n",
        "    stop: Optional[List[str]] = None,\n",
        "    run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "  ) -> str:\n",
        "    session = self.retry_request_session()\n",
        "    payload = {\n",
        "        \"messages\": [\n",
        "          {\n",
        "            \"role\": \"human\",\n",
        "            \"content\": prompt\n",
        "          }\n",
        "      ],\n",
        "      \"model\": 'Maritalk',\n",
        "      \"do_sample\": True,\n",
        "      \"max_tokens\": 2048,\n",
        "      \"temperature\": 0.5,\n",
        "      \"top_p\": 0.95,\n",
        "      \"repetition_penalty\": 1,\n",
        "      \"use_chat_template\": True,\n",
        "      \"stopping_tokens\": ['string']\n",
        "    }\n",
        "    res = session.post('https://chat.maritaca.ai/api/chat/inference',\n",
        "                       json=payload)\n",
        "\n",
        "    if res.status_code == 200:\n",
        "      return res.json()['answer']\n",
        "    else:\n",
        "      print(f'oops... status code {res.status_code}')\n",
        "      return ''\n",
        "\n",
        "  def retry_request_session(self, retries: Optional[int] = 3):\n",
        "    # we setup retry strategy to retry on common errors\n",
        "    retries = Retry(\n",
        "        total=retries,\n",
        "        backoff_factor=0.1,\n",
        "        status_forcelist=[\n",
        "            408,  # request timeout\n",
        "            429,  # too many requests\n",
        "            500,  # internal server error\n",
        "            502,  # bad gateway\n",
        "            503,  # service unavailable\n",
        "            504   # gateway timeout\n",
        "        ]\n",
        "    )\n",
        "    # we setup a session with the retry strategy\n",
        "    session = requests.Session()\n",
        "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "    return session\n",
        "\n",
        "  @property\n",
        "  def _identifying_params(self) -> Mapping[str, Any]:\n",
        "    \"\"\"Get the identifying parameters.\"\"\"\n",
        "    return {\"n\": 1}"
      ],
      "metadata": {
        "id": "CVHCT3pCiwjh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicação\n",
        "\n",
        "A classe acima extende LLM da Langchain para que possamos implementar nossa lógica.\n",
        "\n",
        "O método retry_request_session é um helper que vai resolver pequenos problemas de comunicação que podem acontecer e retomar a chamada fazendo 3 tentativas.\n",
        "\n",
        "Em _call realizamos a chamada a API passando o prompt e os demais parâmetros.\n",
        "\n",
        "A seguir, o teste!"
      ],
      "metadata": {
        "id": "bOhBKUyur5xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = MaritalkLLM()"
      ],
      "metadata": {
        "id": "E3hyJvrismuy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm('Me explique como funciona o SUS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "tDV-_1qxw6pt",
        "outputId": "b5873232-1ef8-412e-c2a8-ca353e0e3ab2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O SUS (Sistema Único de Saúde) é um sistema de saúde pública no Brasil que tem como objetivo garantir o acesso universal e igualitário à saúde para todos os brasileiros. Ele é financiado por recursos do governo federal, estadual e municipal, além de contribuições da população por meio de impostos.\\n\\nO SUS é composto por uma rede de serviços de saúde que inclui hospitais, postos de saúde, clínicas, laboratórios, entre outros. Ele é organizado em três níveis de atenção à saúde: a atenção básica, a atenção de média complexidade e a atenção de alta complexidade.\\n\\nA atenção básica é o primeiro contato da população com o sistema de saúde e é responsável por atender as necessidades de saúde mais comuns, como consultas médicas, exames preventivos e tratamento de doenças crônicas. Ela é realizada em postos de saúde e clínicas da família e é coordenada por equipes de saúde da família.\\n\\nA atenção de média complexidade é responsável por atender casos que exigem uma maior especialização e tecnologia, como exames de imagem, consultas com especialistas e cirurgias eletivas. Ela é realizada em hospitais e clínicas especializadas.\\n\\nA atenção de alta complexidade é responsável por atender casos que exigem alta tecnologia e recursos especializados, como transplantes, tratamento de câncer e traumas graves. Ela é realizada em hospitais de referência e centros de excelência em saúde.\\n\\nO SUS também tem programas de prevenção e controle de doenças, como o Programa Nacional de Imunizações, que oferece vacinas gratuitas para a população, e o Programa Nacional de DST/AIDS, que promove a prevenção e o tratamento da AIDS e outras doenças sexualmente transmissíveis.\\n\\nEm resumo, o SUS é um sistema de saúde público que tem como objetivo garantir o acesso universal e igualitário à saúde para todos os brasileiros, por meio de uma rede de serviços de saúde organizada em três níveis de atenção à saúde: a atenção básica, a atenção de média complexidade e a atenção de alta complexidade. Ele também tem programas de prevenção e controle de doenças.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O SUS (Sistema Único de Saúde) é um sistema de saúde pública no Brasil que tem como objetivo garantir o acesso universal e igualitário à saúde para todos os brasileiros. Ele é financiado por recursos do governo federal, estadual e municipal, além de contribuições da população por meio de impostos.\n",
        "\n",
        "O SUS é composto por uma rede de serviços de saúde que inclui hospitais, postos de saúde, clínicas, laboratórios, entre outros. Ele é organizado em três níveis de atenção à saúde: a atenção básica, a atenção de média complexidade e a atenção de alta complexidade.\n",
        "\n",
        "A atenção básica é o primeiro contato da população com o sistema de saúde e é responsável por atender as necessidades de saúde mais comuns, como consultas médicas, exames preventivos e tratamento de doenças crônicas. Ela é realizada em postos de saúde e clínicas da família e é coordenada por equipes de saúde da família.\n",
        "\n",
        "A atenção de média complexidade é responsável por atender casos que exigem uma maior especialização e tecnologia, como exames de imagem, consultas com especialistas e cirurgias eletivas. Ela é realizada em hospitais e clínicas especializadas.\n",
        "\n",
        "A atenção de alta complexidade é responsável por atender casos que exigem alta tecnologia e recursos especializados, como transplantes, tratamento de câncer e traumas graves. Ela é realizada em hospitais de referência e centros de excelência em saúde.\n",
        "\n",
        "O SUS também tem programas de prevenção e controle de doenças, como o Programa Nacional de Imunizações, que oferece vacinas gratuitas para a população, e o Programa Nacional de DST/AIDS, que promove a prevenção e o tratamento da AIDS e outras doenças sexualmente transmissíveis.\n",
        "\n",
        "Em resumo, o SUS é um sistema de saúde público que tem como objetivo garantir o acesso universal e igualitário à saúde para todos os brasileiros, por meio de uma rede de serviços de saúde organizada em três níveis de atenção à saúde: a atenção básica, a atenção de média complexidade e a atenção de alta complexidade. Ele também tem programas de prevenção e controle de doenças."
      ],
      "metadata": {
        "id": "R20dRP4zdlsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompts mais elaborados\n",
        "\n",
        "Agora que conseguimos integrar, vamos usar um prompt mais sofisticado e ver como o modelo se comporta. A idea a seguir é pedir ao modelo para entender um contexto, extrarir perguntas dele e nos entregar a resposta em um determinado padrão."
      ],
      "metadata": {
        "id": "L7CmNEXFy8ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "O trecho a seguir contem fatos sobre o assunto que ele trata. Sua missão é extrair dele 3 perguntas e organizar a resposta em formato JSON da seguinte maneira:\n",
        "[{\"pergunta1\": \"aqui vai a pergunta extraída\"},{\"pergunta2\": \"aqui vai a pergunta extraída\"}].\n",
        "\n",
        "Contexto:\n",
        "A revolta começou como uma série de protestos contra a cobrança de impostos e a falta de autonomia política para a província do Rio Grande do Sul.\n",
        "Em 1835, Bento Gonçalves liderou uma rebelião que resultou na proclamação da República Rio-Grandense, um governo independente que se opunha ao governo central brasileiro.\n",
        "\"\"\"\n",
        "\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HN0Z-sBGzQYA",
        "outputId": "a2cfeb68-aea4-4524-f0bd-d268aa7f3b85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[\\n{\"pergunta1\": \"Quando começou a Revolução Farroupilha?\"},\\n{\"pergunta2\": \"Quem liderou a Revolução Farroupilha?\"},\\n{\"pergunta3\": \"O que a Revolução Farroupilha buscava?\"}\\n]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integração com Pinecone\n",
        "\n",
        "Para realizar uma integração completa usando exclusivamente o Maritaca, a API precisaria de um endpoint para captura dos embeddings, mas isso ainda não está disponível, então, a seguir iremos utilizar a OpenAI para criar as representações dos textos, enviar para o Pinecone e usar o Maritaca no final do fluxo. Funciona assim:\n",
        "\n",
        "1. Capturamos os textos que queremos trabalhar, neste caso, a Portaria de Consolidação N 1 do Ministério da Saúde.\n",
        "\n",
        "2. Vamos quebrar o texto em pequenas partes.\n",
        "\n",
        "3. Interagir com a OpenAI e capturar os embeddings dos trechos criados.\n",
        "\n",
        "4. Enviar esses trechos para o Pinecone.\n",
        "\n",
        "Perceba que os passos acima são executados uma só vez ou sempre que houver necessidade de atualizar a estrutura. O resultado é uma base com diversos vetores que representam cada um dos trechos que criamos. O Pinecone, ou qualquer banco do mesmo tipo, viabiliza que sejam executadas consultas por similaridade. Dessa forma:\n",
        "\n",
        "1. Agora que temos a base podemos enviar uma pergunta ou um texto qualquer, mas temos que criar a representação da pergunta e neste momento iremos chamar novamente a OpenAI para captura dos embeddings.\n",
        "\n",
        "2. Em seguida, a Langchain interage com o Pinecone e pede para retornar os N vetores que mais se parecem com a pergunta/texto que enviamos.\n",
        "\n",
        "Deste ponto em diante, já temos acesso aos N trechos semelhantes e, portanto, são os que possívelmente respondem a nossa pergunta. Vamos usar eles como contexto do prompt final com Maritaca."
      ],
      "metadata": {
        "id": "2CKaxw0KzoiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://github.com/free-educa/books/blob/main/books/Data%20Science%20do%20zero_%20Primeiras%20-%20Joel%20Grus.pdf\"\n",
        "file_name = \"data_science.pdf\"\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3HxXSckfduB",
        "outputId": "524f2363-d526-414d-c5a9-5100b150d382"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('data_science.pdf', <http.client.HTTPMessage at 0x78e3e74d72e0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "loader = UnstructuredFileLoader(\"https://github.com/free-educa/books/blob/main/books/Data%20Science%20do%20zero_%20Primeiras%20-%20Joel%20Grus.pdf\")"
      ],
      "metadata": {
        "id": "dvQPhEoWznwY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "spnh8rpw_SYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "1b4c80da-c049-4067-97b5-b635f2ae0645"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PDFSyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPDFSyntaxError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c440b526cd76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/document_loaders/pdf.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;34m\"\"\"Load documents.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnstructuredPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/document_loaders/unstructured.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m\"\"\"Load file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"elements\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/document_loaders/pdf.py\u001b[0m in \u001b[0;36m_get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0munstructured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartition_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpartition_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstructured_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/documents/elements.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/file_utils/filetype.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/partition/pdf.py\u001b[0m in \u001b[0;36mpartition_pdf\u001b[0;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, max_partition, include_metadata, metadata_filename, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0mexactly_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return partition_pdf_or_image(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/partition/pdf.py\u001b[0m in \u001b[0;36mpartition_pdf_or_image\u001b[0;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, ocr_languages, max_partition, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         extracted_elements = extractable_elements(\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspooled_to_bytes_io_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/partition/pdf.py\u001b[0m in \u001b[0;36mextractable_elements\u001b[0;34m(filename, file, include_page_breaks)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0minclude_page_breaks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m ):\n\u001b[0;32m--> 102\u001b[0;31m     return _partition_pdf_with_pdfminer(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     ),\n\u001b[1;32m     42\u001b[0m                 )\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/partition/pdf.py\u001b[0m in \u001b[0;36m_partition_pdf_with_pdfminer\u001b[0;34m(filename, file, include_page_breaks)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             elements = _process_pdfminer_pages(\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unstructured/partition/pdf.py\u001b[0m in \u001b[0;36m_process_pdfminer_pages\u001b[0;34m(fp, filename, include_page_breaks)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0melements\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mElement\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/high_level.py\u001b[0m in \u001b[0;36mextract_pages\u001b[0;34m(pdf_file, password, page_numbers, maxpages, caching, laparams)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFPageAggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlaparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFPageInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         for page in PDFPage.get_pages(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_numbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxpages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfpage.py\u001b[0m in \u001b[0;36mget_pages\u001b[0;34m(cls, fp, pagenos, maxpages, password, caching, check_extractable)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Create a PDF document object that stores the document structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Check if the document allows text extraction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# If not, warn the user and proceed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfdocument.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, password, caching, fallback)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPDFSyntaxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No /Root object! - Is this really a PDF?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mLITERAL_CATALOG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPDFSyntaxError\u001b[0m: No /Root object! - Is this really a PDF?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'Você tem {len(data)} documento(s) na base')\n",
        "print (f'Há {len(data[0].page_content)} caracteres no documento')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wBNh_VG_OD7",
        "outputId": "f90ad0de-a2cd-4029-d2f8-5507420b6f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Você tem 1 documento(s) na base\n",
            "Há 58236 caracteres no documento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100, separators=['\\n', ' ', ''])\n",
        "texts = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "ceoaIfvi_2hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'Agora há {len(texts)} documentos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FYQmtVtAAVM",
        "outputId": "6cf5595e-dab1-4238-b072-135dbfd91d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agora há 152 documentos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[50].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qLVU_xlWAGMx",
        "outputId": "f96d1030-54b2-42ca-91af-f39fb1f67cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.3.1 Sacadas e microssacadas\\n\\nAs sacadas e microssacadas são tipos de movimentos oculares. As sacadas são\\n\\nmovimentos simultâneos de ambos os olhos em duas ou mais fases para fixação na mesma\\n\\ndireção (CASSIN; SOLOMON, 1990). As sacadas podem ser usadas para estudar o\\n\\ncomportamento ocular, os Movimentos Rápidos dos Olhos, tradicionalmente denominados\\n\\npela sigla em inglês de Rapid Eye Movements (REM) durante o estágio do sono, além de'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração da OpenAI e Pinecone\n",
        "\n",
        "Recomendo ler como o Pinecone funciona, há muita documentação pela internet.\n",
        "\n",
        "O código a seguir realiza a integração entre Pinecone e OpenAI e para isso você vai precisar de chaves. Para manter as que uso de forma privada, criei um arquivo com o seguinte formato:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"openai\": \"key\",\n",
        "    \"pinecone_key\": \"key\",\n",
        "    \"pinecone_env\": \"env\",\n",
        "    \"index_name\": \"idx\"\n",
        "}\n",
        "```\n",
        "\n",
        "Chamei de keys.json e coloquei na raiz do colab. Você pode fazer o mesmo para testar este notebook."
      ],
      "metadata": {
        "id": "5RvC7gq7CHgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import pinecone\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "yBo08jDEAcj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b90c4c0-c25c-45a9-d9b3-8f984226070d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "embed_model = \"text-embedding-ada-002\"\n",
        "\n",
        "res = openai.Embedding.create(\n",
        "    input=texts[200].page_content, engine=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "IX2626EafIic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPcF0owOfWID",
        "outputId": "d7bb88d4-945c-4309-a336-4f442a694a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['object', 'data', 'model', 'usage'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
        "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
        "PINECONE_API_ENV = os.environ['PINECONE_API_ENV']\n",
        "INDEX_NAME = 'compilers-book'"
      ],
      "metadata": {
        "id": "kPmRWM9WAvwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "LTqfAXzrdnr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_API_ENV\n",
        ")\n",
        "index_name = INDEX_NAME"
      ],
      "metadata": {
        "id": "EW6Q-oY6Dks0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pinecone.from_existing_index()"
      ],
      "metadata": {
        "id": "laCOXqbRc9w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use o código a seguir para criar a base\n",
        "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name, namespace='compilers_book_p1')\n",
        "\n",
        "# Use o código a seguir se já tiver um índice criado\n",
        "# docsearch = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)"
      ],
      "metadata": {
        "id": "pgHNDerwEeW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c9b010-d757-4067-8124-024f7ceb2d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-gahvafdz6yYTOuv97HO8hW1p on tokens per min. Limit: 150000 / min. Current: 145675 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-gahvafdz6yYTOuv97HO8hW1p on tokens per min. Limit: 150000 / min. Current: 143845 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-gahvafdz6yYTOuv97HO8hW1p on tokens per min. Limit: 150000 / min. Current: 141557 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-gahvafdz6yYTOuv97HO8hW1p on tokens per min. Limit: 150000 / min. Current: 139693 / min. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain.vectorstores import FAISS\n",
        "import pickle\n",
        "\n",
        "def store_embeddings(docs, embeddings, sotre_name, path):\n",
        "\n",
        "    vectorStore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    with open(f\"{path}/faiss_{sotre_name}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(vectorStore, f)\n",
        "\n",
        "def load_embeddings(sotre_name, path):\n",
        "    with open(f\"{path}/faiss_{sotre_name}.pkl\", \"rb\") as f:\n",
        "        VectorStore = pickle.load(f)\n",
        "    return VectorStore\n"
      ],
      "metadata": {
        "id": "HfDb_80Aap43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = FAISS.from_texts([t.page_content for t in texts], embeddings)"
      ],
      "metadata": {
        "id": "xUGe9aLMcHYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base construída\n",
        "\n",
        "Agora temos nossa base vetorizada! Nosso PDF contendo os dados da Portaria de Consolidação já está no Pinecone, vamos testar!\n",
        "\n",
        "A variável query vai armazenar o texto que será usado para a pesquisa por similaridade. Note que ao criar o objeto docsearch a variável embeddings foi passada como parâmetro. Ela será usada para criar uma representação da query e comparar com os dados contidos no Pinecone. Até o momento, a Maritaca não tem essa opção de criar embeddings, então vamos usar a OpenAI mesmo."
      ],
      "metadata": {
        "id": "u7MeabBwFVy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Como é a bandeira do SUS?\" # faça uma pergunta ou escreva um texto.\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "HQANoVRkFg4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tegUBCIDGgdg",
        "outputId": "a7bb3867-0568-4dc1-df45-339cec2d3a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='§ 2º A Bandeira do SUS poderá ser confeccionada em quaisquer dimensões, desde que obedecidas as características e proporções estabelecidas no modelo aprovado por este Capítulo. (Origem: PRT MS/GM 82/2014, Art. 2º, § 2º)\\n\\nArt. 13. A Bandeira do SUS será hasteada diariamente em todos os prédios dos órgãos e entidades integrantes da estrutura regimental do Ministério da Saúde, em todo o território nacional. (Origem: PRT MS/GM 82/2014, Art. 3º)\\n\\nParágrafo Único. As esferas estaduais, do Distrito Federal e municipais do SUS poderão adotar o mesmo procedimento de que trata o \"caput\" em seus estabelecimentos de saúde, desde que obedecidos os critérios estabelecidos neste Capítulo. (Origem: PRT MS/GM 82/2014, Art. 3º, Parágrafo Único)\\n\\nCAPÍTULO II DA RELAÇÃO NACIONAL DE AÇÕES E SERVIÇOS DE SAÚDE (RENASES)', metadata={}),\n",
              " Document(page_content='Art. 10. Os direitos e deveres dispostos neste Título constituem a Carta dos Direitos dos Usuários da\\n\\nSaúde. (Origem: PRT MS/GM 1820/2009, Art. 9º)\\n\\nParágrafo Único. A Carta dos Direitos dos Usuários da Saúde deverá ser disponibilizada a todas as pessoas por meios físicos e na internet, no seguinte endereço eletrônico: www.saude.gov.br. (Origem: PRT MS/GM 1820/2009, Art. 9º, Parágrafo Único)\\n\\nTÍTULO II DA ORGANIZAÇÃO\\n\\nCAPÍTULO I DA BANDEIRA DO SUS\\n\\nArt. 11. Fica instituída a Bandeira do Sistema Único de Saúde (SUS). (Origem: PRT MS/GM 82/2014,\\n\\nArt. 1º)\\n\\nArt. 12. A Bandeira do SUS possuirá formato retangular e será formada pela associação do símbolo, do\\n\\nlogotipo e do nome institucional em azul sobre fundo branco. (Origem: PRT MS/GM 82/2014, Art. 2º)\\n\\n§ 1º Os elementos técnicos a serem observados na confecção da Bandeira do SUS deverão estar em consonância com o disposto no Manual de Identidade Visual do SUS vigente. (Origem: PRT MS/GM 82/2014, Art. 2º, § 1º)', metadata={}),\n",
              " Document(page_content='Parágrafo Único. A programação visual a que se refere o caput deverá incorporar, de forma complementar, a marca geral do governo de cada ente copartícipe da instalação e custeio da Unidade de Saúde. (Origem: PRT MS/GM 2838/2011, Art. 1º, Parágrafo Único)\\n\\nArt. 525. As marcas nacionais, componente indissociável que caracteriza cada Unidade de Saúde pelos serviços que oferece, devem ser aplicadas conforme estabelecido neste Título como condição indispensável para a habilitação das unidades e devem ser consideradas nos sistemas de controle e monitoramento de seus serviços. (Origem: PRT MS/GM 2838/2011, Art. 2º)\\n\\nArt. 526. Para cumprimento do disposto neste Título, deverá ser observado o conteúdo exposto no \"Guia de Sinalização das Unidades e Serviços do SUS\", que se encontra disponível no endereço eletrônico http://portalsaude.saude.gov.br/index.php/cidadao/principal/guia-de-sinalizacao. (Origem: PRT MS/GM 2838/2011, Art. 4º)\\n\\nTÍTULO X DAS DATAS COMEMORATIVAS E DOS PRÊMIOS DA SAÚDE', metadata={}),\n",
              " Document(page_content='§ 2º A pesquisa de satisfação do atendimento contida na Carta SUS será respondida por meio de cartão- resposta destacável, que terá o porte pago pelo Ministério da Saúde, bastando preenchê-lo e entregá-lo ao carteiro, agência ou caixa de coleta da Empresa Brasileira de Correios e Telégrafos (Correios). (Origem: PRT MS/GM 1570/2015, Art. 4º, § 2º)\\n\\n§ 3º Caso seja preferência do cidadão, a pesquisa de satisfação poderá ser respondida através do Disque Saúde 136, do DOGES/SGEP/MS, ou pelo endereço eletrônico www.saude.gov.br/cartasus. (Origem: PRT MS/GM 1570/2015, Art. 4º, § 3º)\\n\\nArt. 124. Caso o cidadão discorde dos dados constantes na Carta SUS, verifique que houve algum tipo de cobrança por parte do profissional ou da unidade de saúde ou até mesmo nunca tenha passado pelo procedimento citado no documento, então deverá entrar em contato com o Disque Saúde 136, do DOGES/SGEP/MS, para registrar sua manifestação. (Origem: PRT MS/GM 1570/2015, Art. 5º)', metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integração final\n",
        "\n",
        "Agora vamos usar os textos vindos do Pinecone e pedir para nosso LLM, o MariTalk, criar uma resposta adequada."
      ],
      "metadata": {
        "id": "PdOexA_rGtWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "PROMPT = \"\"\"\n",
        "Use os trechos a seguir para responder a pergunta no final. Se você não souber a resposta, apenas diga que não sabe, não tente criar uma resposta.\n",
        "\n",
        "{context}\n",
        "\n",
        "Pergunta: {question}\n",
        "Resposta:\n",
        "\"\"\"\n",
        "\n",
        "chain_prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=PROMPT)\n",
        "\n",
        "# note a variável llm sendo passada abaixo, ela é o Maritaca\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True, prompt=chain_prompt)"
      ],
      "metadata": {
        "id": "J5-b0BSXG6En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Como foi realizado o processamento de sinais?\" # faça uma pergunta ou escreva um texto.\n",
        "\n",
        "# no exemplo abaixo reduzimos o número de documentos para caber na janela do\n",
        "# Maritaca\n",
        "docs = docsearch.similarity_search(query, k=5)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fGj09opwG-oB",
        "outputId": "80d4b0fc-a3fd-48ea-bbd6-2a65dab89829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Use os trechos a seguir para responder a pergunta no final. Se você não souber a resposta, apenas diga que não sabe, não tente criar uma resposta.\n",
            "\n",
            "foram usados métodos de análise computacional na linguagem Python, inicialmente fazendo o\n",
            "\n",
            "pré-processamento desses dados, para em seguida encontrar dois tipos de movimentos\n",
            "\n",
            "característicos de sinais eletrooculográficos: piscadas e sacadas. Para detecção desses eventos\n",
            "\n",
            "utilizamos um algoritmo de código aberto e semi-automático. Foram avaliadas as correlações\n",
            "\n",
            "de Spearman entre a quantidade total de eventos oculares e as pontuações obtidas. A partir\n",
            "\n",
            "3.3\n",
            "\n",
            "Seleção e tratamento dos dados......................................................................... 24\n",
            "\n",
            "3.4\n",
            "\n",
            "Algoritmo para detecção de piscadas e sacadas..............................................\n",
            "\n",
            "26\n",
            "\n",
            "3.5\n",
            "\n",
            "Ferramenta de seleção de dados para o treinamento do EOGERT............... 27\n",
            "\n",
            "3.6\n",
            "\n",
            "Aplicação do algoritmo......................................................................................\n",
            "\n",
            "28\n",
            "\n",
            "3.7\n",
            "\n",
            "em azul o sinal com o filtro FIR da biblioteca MNE. (D) Sinal EOGH, em cinza escuro o sinal original, em cinza claro o sinal filtrado pelo MNE e em azul o sinal suavizado após aplicação da função eog_clean com filtro Butterworth da biblioteca Neurokit. Fonte: Elaborado pelo autor.\n",
            "\n",
            "eventos oculares (MAKOWSKI et al., 2021). Na figura 3B e 3D é perceptível a diferença\n",
            "\n",
            "entre o sinal original, o sinal após a primeira filtragem e o sinal após a aplicação do método de\n",
            "\n",
            "suavização do neurokit.\n",
            "\n",
            "29\n",
            "\n",
            "Inicialmente haviam 32 sujeitos, mas um foi descartado pois os dados registrados\n",
            "\n",
            "desse sujeito estavam com baixa qualidade impossibilitando a detecção, sendo assim ficamos\n",
            "\n",
            "com 31 participantes, 16 na função presa e 15 na função predador. Como cada participante\n",
            "\n",
            "Figura 3 - Comparações do sinal original x filtro MNE x filtro Neurokit. (A) Sinal EOGV, em cinza o sinal original, em vermelho o sinal com o filtro FIR da biblioteca MNE. (B) Sinal EOGv, em cinza escuro o sinal original, em cinza claro o sinal filtrado pelo MNE e em vermelho o sinal suavizado após aplicação da função eog_clean com filtro Butterworth da biblioteca Neurokit. (C) Sinal EOGH, em cinza o sinal original, em azul o sinal com o filtro FIR da biblioteca MNE. (D) Sinal EOGH, em cinza escuro o sinal\n",
            "\n",
            "Pergunta: Como foi realizado o processamento de sinais?\n",
            "Resposta:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Os sinais foram processados por meio de técnicas de análise computacional na linguagem Python. Inicialmente, houve pré-processamento dos dados, que incluiu a aplicação de um algoritmo de código aberto e semi-automático para a detecção de dois tipos de movimentos característicos de sinais eletrooculográficos: piscadas e sacadas. Foram avaliadas as correlações de Spearman entre a quantidade total de eventos oculares e as pontuações obtidas. Além disso, foram utilizados filtros para suavizar os sinais, como o filtro FIR da biblioteca MNE e a função eog\\\\_clean com filtro Butterworth da biblioteca Neurokit. Foi possível observar a diferença entre o sinal original, o sinal após a primeira filtragem e o sinal após a aplicação do método de suavização do neurokit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os sinais foram processados por meio de técnicas de análise computacional na linguagem Python. Inicialmente, houve pré-processamento dos dados, que incluiu a aplicação de um algoritmo de código aberto e semi-automático para a detecção de dois tipos de movimentos característicos de sinais eletrooculográficos: piscadas e sacadas. Foram avaliadas as correlações de Spearman entre a quantidade total de eventos oculares e as pontuações obtidas. Além disso, foram utilizados filtros para suavizar os sinais, como o filtro FIR da biblioteca MNE e a função eog\\_clean com filtro Butterworth da biblioteca Neurokit. Foi possível observar a diferença entre o sinal original, o sinal após a primeira filtragem e o sinal após a aplicação do método de suavização do neurokit."
      ],
      "metadata": {
        "id": "yDY3r4FhidNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"O que são sacadas?\" # faça uma pergunta ou escreva um texto.\n",
        "\n",
        "docs = docsearch.similarity_search(query, k=5)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TPsrRynKjhA0",
        "outputId": "b69586f3-e53c-487d-d8db-ad6fa40b436f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Use os trechos a seguir para responder a pergunta no final. Se você não souber a resposta, apenas diga que não sabe, não tente criar uma resposta.\n",
            "\n",
            "1.3.1 Sacadas e microssacadas\n",
            "\n",
            "As sacadas e microssacadas são tipos de movimentos oculares. As sacadas são\n",
            "\n",
            "movimentos simultâneos de ambos os olhos em duas ou mais fases para fixação na mesma\n",
            "\n",
            "direção (CASSIN; SOLOMON, 1990). As sacadas podem ser usadas para estudar o\n",
            "\n",
            "comportamento ocular, os Movimentos Rápidos dos Olhos, tradicionalmente denominados\n",
            "\n",
            "pela sigla em inglês de Rapid Eye Movements (REM) durante o estágio do sono, além de\n",
            "\n",
            "consolidado no meio acadêmico, possuir diversas bibliotecas para análise, o laboratório já\n",
            "\n",
            "17\n",
            "\n",
            "possui equipamentos para esse tipo de análise, e, ainda, os dados que serão utilizados já foram\n",
            "\n",
            "coletados usando EOG.\n",
            "\n",
            "1.3 Padrões oculares\n",
            "\n",
            "Existem alguns padrões oculares de interesse a serem analisados neste trabalho, entre\n",
            "\n",
            "eles piscadas e sacadas, não serão analisados microssacadas e nem períodos de fixação.\n",
            "\n",
            "1.3.1 Sacadas e microssacadas\n",
            "\n",
            "Nesta seção serão apresentados os resultados obtidos e em seguida as discussões\n",
            "\n",
            "sobre eles.\n",
            "\n",
            "Inicialmente, é interessante verificar a distribuição dos dados gerados pelo algoritmo\n",
            "\n",
            "EOGERT na detecção dos eventos oculares (piscadas e sacadas)(figura 6).\n",
            "\n",
            "de ataque (GSA) (figura 7 e 9A), ou seja, quanto maior o ganho de sacadas menor será o GSA\n",
            "\n",
            "e vice-versa. Ainda vale ressaltar que o score de ataque está ligado a diferença entre vezes que\n",
            "\n",
            "o jogador matou e morreu dentro do jogo. Para essa situação, a nossa hipótese é que o\n",
            "\n",
            "indivíduo que tem um ganho maior de sacadas seja um jogador mais parado e que joga mais\n",
            "\n",
            "escondido, com isso acaba observando mais o ambiente, porém acaba sendo caçado de forma\n",
            "\n",
            "37\n",
            "\n",
            "5 DISCUSSÕES\n",
            "\n",
            "Os resultados obtidos levaram a pensar sobre quais as possíveis causas das\n",
            "\n",
            "correlações entre as variáveis de jogo e as variáveis de eventos oculares. Para lidar com isso\n",
            "\n",
            "levantamos algumas possíveis hipóteses.\n",
            "\n",
            "5.1 Presa\n",
            "\n",
            "Para a presa, foi observada uma correlação negativa entre o GS e o ganho do score\n",
            "\n",
            "de ataque (GSA) (figura 7 e 9A), ou seja, quanto maior o ganho de sacadas menor será o GSA\n",
            "\n",
            "Pergunta: O que são sacadas?\n",
            "Resposta:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As sacadas são movimentos simultâneos de ambos os olhos em duas ou mais fases para fixação na mesma direção. Elas podem ser usadas para estudar o comportamento ocular, os Movimentos Rápidos dos Olhos (REM) durante o estágio do sono, além de serem usadas para análise de dados coletados usando EOG.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As sacadas são movimentos simultâneos de ambos os olhos em duas ou mais fases para fixação na mesma direção. Elas podem ser usadas para estudar o comportamento ocular, os Movimentos Rápidos dos Olhos (REM) durante o estágio do sono, além de serem usadas para análise de dados coletados usando EOG."
      ],
      "metadata": {
        "id": "O0HQIquzj6Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Quais os métodos utilizados?\" # faça uma pergunta ou escreva um texto.\n",
        "\n",
        "docs = docsearch.similarity_search(query, k=5)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PfN-EE08nIUn",
        "outputId": "4ab0f719-6bc3-432e-95a6-d0dce89c0399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Use os trechos a seguir para responder a pergunta no final. Se você não souber a resposta, apenas diga que não sabe, não tente criar uma resposta.\n",
            "\n",
            "18\n",
            "\n",
            "2\n",
            "\n",
            "OBJETIVOS.......................................................................................................\n",
            "\n",
            "19\n",
            "\n",
            "3\n",
            "\n",
            "METODOLOGIA............................................................................................... 20\n",
            "\n",
            "3.1\n",
            "\n",
            "O experimento..................................................................................................... 20\n",
            "\n",
            "3.2\n",
            "\n",
            "Software usado para as análises........................................................................ 22\n",
            "\n",
            "3.3\n",
            "\n",
            "Os modelos de RO podem ser usados em tela ou por meio de dispositivos vestíveis,\n",
            "\n",
            "como por exemplo um equipamento de RO semelhante a uma armação de óculos. Como\n",
            "\n",
            "citado anteriormente, o RO pode ser utilizado para estudar padrões oculares. Dentre esses\n",
            "\n",
            "padrões ele é capaz de captar dados de sacadas, piscadas, microssacadas e fixação.\n",
            "\n",
            "16\n",
            "\n",
            "1.2.2 EOG\n",
            "\n",
            "O segundo método que também é necessário conhecer é a Eletro-oculografia (EOG).\n",
            "\n",
            "16\n",
            "\n",
            "1.2.2 EOG\n",
            "\n",
            "O segundo método que também é necessário conhecer é a Eletro-oculografia (EOG).\n",
            "\n",
            "O EOG faz uso de eletrodos em contato com a face para coletar os dados. Diferente do que se\n",
            "\n",
            "pensa, a técnica de EOG não mede a contração dos músculos oculares, na verdade ela é\n",
            "\n",
            "utilizada para medir a diferença de potencial elétrico fisiológico entre a córnea e a retina, mais\n",
            "\n",
            "especificamente entre a córnea e o epitélio pigmentado da retina (EPR). Adota-se a córnea\n",
            "\n",
            "técnica (ARDEN; BARRADA; KELSEY, 1962).\n",
            "\n",
            "1.2.3 EOG x Eye tracking\n",
            "\n",
            "Os dois métodos possuem vantagens e desvantagens. O método de RO por exemplo,\n",
            "\n",
            "não é afetado pela rede elétrica e também não tem problema com a variação da resistência da\n",
            "\n",
            "pele,\n",
            "\n",
            "já o EOG consegue registrar informações mesmo quando o sujeito está de olhos\n",
            "\n",
            "fechados, o RO tem perda de dados durante as piscadas. Atualmente, os dois métodos têm\n",
            "\n",
            "problema com movimentação durante o registro de dados (MÜLLER et al., 2016)\n",
            "\n",
            "foram usados métodos de análise computacional na linguagem Python, inicialmente fazendo o\n",
            "\n",
            "pré-processamento desses dados, para em seguida encontrar dois tipos de movimentos\n",
            "\n",
            "característicos de sinais eletrooculográficos: piscadas e sacadas. Para detecção desses eventos\n",
            "\n",
            "utilizamos um algoritmo de código aberto e semi-automático. Foram avaliadas as correlações\n",
            "\n",
            "de Spearman entre a quantidade total de eventos oculares e as pontuações obtidas. A partir\n",
            "\n",
            "Pergunta: Quais os métodos utilizados?\n",
            "Resposta:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Os métodos utilizados foram o Registro Ocular (RO) e a Eletro-oculografia (EOG). O RO é um método que capta dados de sacadas, piscadas, microssacadas e fixação, enquanto o EOG mede a diferença de potencial elétrico fisiológico entre a córnea e a retina. Ambos os métodos têm vantagens e desvantagens, como a falta de dados durante as piscadas no RO e a falta de dados durante o fechamento dos olhos no EOG.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As três abstrações críticas que os procedimentos oferecem para permitir a construção de programas não triviais são:\n",
        "\n",
        "1. Abstração de chamada de procedimento: As linguagens procedurais admitem uma abstração para chamadas de procedimento. Cada linguagem tem um mecanismo padrão para chamar um procedimento e mapear um conjunto de argumentos, ou parâmetros, do espaço de nomes do chamador para o espaço de nomes do chamado. Esta abstração normalmente inclui um mecanismo para retornar o controle ao chamador e continuar a execução no ponto imediatamente após a chamada. A maioria das linguagens permite que um procedimento retorne um ou mais valores ao chamador. O uso de convenções de ligação padrão, às vezes chamadas sequências de chamada, permite que o programador chame código escrito e compilado por outras pessoas e em outras ocasiões, o que, por sua vez, permite que a aplicação chame rotinas de biblioteca e serviços de sistema.\n",
        "2. Abstração de armazenamento: Procedimentos criam um ambiente de execução controlado; cada procedimento tem seu próprio espaço de armazenamento nomeado privado. Isso significa que as variáveis e parâmetros utilizados por um procedimento não são acessíveis a outros procedimentos, a menos que explicitamente compartilhados. Isso torna possível a modularidade, permitindo que os programadores dividam um grande sistema em componentes menores e mais gerenciáveis.\n",
        "3. Abstração de interface: Procedimentos ajudam a definir interfaces entre componentes do sistema; interações entre componentes normalmente são estruturadas por meio de chamadas de procedimento. Isso permite que os programadores possam escrever código que interage com outros componentes sem precisar conhecer detalhes internos desses componentes. Em vez disso, eles podem se concentrar em entender a interface pública do componente, que é definida por meio de chamadas de procedimento."
      ],
      "metadata": {
        "id": "khBgvj4knb4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.similarity_search(\"livre de contexto\", k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0UtvSiwdRJf",
        "outputId": "b738daa8-f9dd-4428-f367-9f54c284c4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRLKb9J-Iy8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}